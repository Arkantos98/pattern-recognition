{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de patrones: Clasificación\n",
    "### Ramón Soto C. [(rsotoc@moviquest.com)](mailto:rsotoc@moviquest.com/)\n",
    "![ ](images/blank.png)\n",
    "![agents](images/binary_data_under_a_magnifying.jpg)\n",
    "[ver en nbviewer](http://nbviewer.ipython.org/github/rsotoc/pattern-recognition/blob/master/Clasificación%20II.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 2px;\">\n",
    "\n",
    "## Clasificación de textos / Minería de opiniones\n",
    "\n",
    "La **clasificación de textos** es un área del *procesamiento de lenguaje natural* que ha ganado gran importancia en los útlimos años debido a la *minería de opiniones* (o *análisis de sentimientos*).\n",
    "\n",
    "La minería de opiniones busca detectar cuál es la postura de una comunidad en torno a un tema en particular: La aceptación a un programa de gobierno, la imagen de un producto, la recepción de una película, etc. La forma tradicional de atacar este problema ha sido a través de encuestas que son costosas, tardadas y tendenciosas: el diseño siempre está sesgado a lo que el encuestador quiere medir y las respuestas están restringidas a las opciones que el evaluado puede elegir y a la solemnidad de la encuesta.\n",
    "\n",
    "![ ](images/de10.png)\n",
    "\n",
    "Una mejor opción de concoer la verdadera opinión de la gente es a través de analizar sus opiniones abiertas, por ejemplo a través de sus publicaciones en redes sociales.\n",
    "\n",
    "![ ](images/social.jpg)\n",
    "\n",
    "El clasificador bayesiano ingenuo es uno de los métodos más utilizados en análisis de textos. Los dos modelos más utilizados para este fin son el modelo de Bernoulli y el modelo multinomial con pesos tf–idf.\n",
    "\n",
    "El problema de identificar la polaridad en revisiones de películas es un ejercicio interesante debido a las expresiones utilizadas que suelen ser contradictorias.\n",
    "\n",
    "![ ](images/deadpoolcritic.png)\n",
    "\n",
    "En el siguiente ejercició utilizaremos el clasificador bayesiano ingenuo para clasificar automáticamente la polaridad de revisiones de películas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "os.chdir('Data sets/Movies Reviews')\n",
    "movies_reviews = pd.read_csv(\"labeledTrainData.tsv\", sep='\\t')\n",
    "# Limpiar los documentos\n",
    "movies_reviews.review = list(map(lambda row: re.sub(\"[^a-zA-Z]\", \" \", \n",
    "                                BeautifulSoup(row, \"lxml\").get_text().lower()), \n",
    "                                 movies_reviews.review))\n",
    "# Agregar una columna con la conversión de mensajes a listas de palabras\n",
    "movies_reviews[\"words\"] = list(map(lambda row: row.split(), movies_reviews.review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo simple de clasificador Bernoulli bayesiano ingenuo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Regresa el vector de características de un documento\n",
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = []\n",
    "    for word in word_features:\n",
    "        if (word in document_words) :\n",
    "            features.append(1)\n",
    "        else :\n",
    "            features.append(0)\n",
    "    return features\n",
    "\n",
    "# Construcción de la Bolsa de palabras\n",
    "all_words = nltk.FreqDist(w.lower() for wl in dfBernoulli.words for w in wl)\n",
    "word_features = list(all_words)[:4000]\n",
    "\n",
    "# Vectores de características de la colección de documentos\n",
    "featuresets = [document_features(d) for d in dfBernoulli[\"words\"]]\n",
    "\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "#targetsets = [c for (d,c) in documents]\n",
    "targetsets = np.array([int(x) for x in dfBernoulli.sentiment])\n",
    "train_targetset, test_targetset = targetsets[100:], targetsets[:100]\n",
    "\n",
    "# Entrenamiento de un clasificador Bernouilli Bayes ingenuo\n",
    "clfB = BernoulliNB(alpha=1.0, class_prior=None, fit_prior=False)\n",
    "clfB.fit(train_set, train_targetset)\n",
    "\n",
    "# Pruebas del clasificador\n",
    "class_predict_train = clfB.predict(train_set)\n",
    "fails_train = np.sum(train_targetset  != class_predict_train)\n",
    "print(\"Puntos mal clasificados en el conjunto de entrenamiento: {} de {} ({}%)\\n\"\n",
    "      .format(fails_train, len(train_set), 100*fails_train/len(train_set)))\n",
    "class_predict_test = clfB.predict(test_set)\n",
    "fails_test = np.sum(test_targetset  != class_predict_test)\n",
    "print(\"Puntos mal clasificados en el conjunto de prueba: {} de {} ({}%)\\n\"\n",
    "      .format(fails_test, len(test_set), 100*fails_test/len(test_targetset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo simple de clasificador bayesiano ingenuo multinomial con *tf–idf*\n",
    "\n",
    "En el siguiente ejemplo, se repite el ejemplo previo, pero utilizando el modelo multinomial con pesos [*tf–idf*](https://en.wikipedia.org/wiki/Tf–idf) del clasificador bayesiano ingenuo. \n",
    "\n",
    "#### tf–idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "input_vectorizer = TfidfVectorizer(stop_words='english', min_df=3, max_df = 0.8)\n",
    "\n",
    "Sentiments = np.array([int(x) for x in df.sentiment])\n",
    "X_data = input_vectorizer.fit_transform(df.review)\n",
    "\n",
    "cut = 4 * X_data.shape[0] // 5\n",
    "train = X_data[:cut]\n",
    "train_sent = Sentiments[:cut]\n",
    "test = X_data[cut:]\n",
    "test_sent = Sentiments[cut:]\n",
    "\n",
    "\n",
    "clfM = MultinomialNB()\n",
    "\n",
    "probas = clfM.fit(train, train_sent).predict(train)\n",
    "correct_predictions = [train_sent[i]==probas[i] for i in range(0,len(probas)-1)]\n",
    "likelihood = sum(correct_predictions)*100.0/len(probas)\n",
    "print(sum(correct_predictions), len(probas), likelihood)\n",
    "\n",
    "probas2 = clfM.predict(test)\n",
    "correct_predictions2 = [test_sent[i]==probas2[i] for i in range(0,len(probas2)-1)]\n",
    "likelihood2 = sum(correct_predictions2)*100.0/len(probas2)\n",
    "print(sum(correct_predictions2), len(probas2), likelihood2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 3px;\">\n",
    "\n",
    "### Tarea 6\n",
    "\n",
    "* Realice pruebas de los clasificadores bayesianos ingenuos sobre sus datos.\n",
    "\n",
    "**Fecha de entrega**: Martes 4 de octubre."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
