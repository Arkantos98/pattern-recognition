{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de patrones: Clasificación\n",
    "### Ramón Soto C. [(rsotoc@moviquest.com)](mailto:rsotoc@moviquest.com/)\n",
    "![ ](images/blank.png)\n",
    "![agents](images/binary_data_under_a_magnifying.jpg)\n",
    "[ver en nbviewer](http://nbviewer.ipython.org/github/rsotoc/pattern-recognition/blob/master/Clasificación%20II-B.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 2px;\">\n",
    "\n",
    "## Clasificación de textos / Minería de opiniones\n",
    "\n",
    "La **clasificación de textos** es un área del *procesamiento de lenguaje natural* que ha ganado gran importancia en los útlimos años debido a la *minería de opiniones* (o *análisis de sentimientos*).\n",
    "\n",
    "La minería de opiniones busca detectar cuál es la postura de una comunidad en torno a un tema en particular: La aceptación a un programa de gobierno, la imagen de un producto, la recepción de una película, etc. La forma tradicional de atacar este problema ha sido a través de encuestas que son costosas, tardadas y tendenciosas: el diseño siempre está sesgado a lo que el encuestador quiere medir y las respuestas están restringidas a las opciones que el evaluado puede elegir y a la solemnidad de la encuesta.\n",
    "\n",
    "![ ](images/de10.png)\n",
    "\n",
    "Una mejor opción de conocer la verdadera opinión de la gente es a través de analizar sus opiniones abiertas, por ejemplo a través de sus publicaciones en redes sociales.\n",
    "\n",
    "![ ](images/social.jpg)\n",
    "\n",
    "El clasificador bayesiano ingenuo es uno de los métodos más utilizados en análisis de textos. Los dos modelos más utilizados para este fin son el modelo de Bernoulli y el modelo multinomial con pesos tf–idf.\n",
    "\n",
    "El problema de identificar la polaridad en revisiones de películas es un ejercicio interesante debido a las expresiones utilizadas que suelen ser contradictorias.\n",
    "\n",
    "![ ](images/deadpoolcritic.png)\n",
    "\n",
    "<hr style=\"border-width: 2px;\">\n",
    "\n",
    "### Revisiones de películas\n",
    "\n",
    "En el siguiente ejercició utilizaremos el clasificador bayesiano ingenuo para clasificar automáticamente la polaridad de revisiones de películas. Emplearemos los datos disponibles en el sitio de Kaggle ([Tutorial](https://www.kaggle.com/c/word2vec-nlp-tutorial/data)). Para preparar los datos utilizaremos la biblioteca [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#) para eliminar posibles etiquetas de *markup* y eliminaemos todos los elementos no alfabéticos. También eliminaremos, del conjunto de palabras representativas, las llamadas [palabras vacías (*stop words*)](https://en.wikipedia.org/wiki/Stop_words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>with all this stuff going down at the moment w...</td>\n",
       "      <td>[stuff, going, moment, mj, started, listening,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>the classic war of the worlds   by timothy hi...</td>\n",
       "      <td>[classic, war, worlds, timothy, hines, enterta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>the film starts with a manager  nicholas bell ...</td>\n",
       "      <td>[film, starts, manager, nicholas, bell, giving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>it must be assumed that those who praised this...</td>\n",
       "      <td>[must, assumed, praised, film, greatest, filme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>superbly trashy and wondrously unpretentious  ...</td>\n",
       "      <td>[superbly, trashy, wondrously, unpretentious, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review  \\\n",
       "0  5814_8          1  with all this stuff going down at the moment w...   \n",
       "1  2381_9          1   the classic war of the worlds   by timothy hi...   \n",
       "2  7759_3          0  the film starts with a manager  nicholas bell ...   \n",
       "3  3630_4          0  it must be assumed that those who praised this...   \n",
       "4  9495_8          1  superbly trashy and wondrously unpretentious  ...   \n",
       "\n",
       "                                               words  \n",
       "0  [stuff, going, moment, mj, started, listening,...  \n",
       "1  [classic, war, worlds, timothy, hines, enterta...  \n",
       "2  [film, starts, manager, nicholas, bell, giving...  \n",
       "3  [must, assumed, praised, film, greatest, filme...  \n",
       "4  [superbly, trashy, wondrously, unpretentious, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from nltk.corpus import stopwords \n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "os.chdir('Data sets/Movies Reviews')\n",
    "movies_reviews = pd.read_csv(\"labeledTrainData.tsv\", sep='\\t')\n",
    "\n",
    "# Limpiar los documentos. Conservar sólo plabras (alfabéticas) y pasar a minúsculas\n",
    "movies_reviews.review = list(map(lambda row: re.sub(\"[^a-zA-Z]\", \" \", \n",
    "                                BeautifulSoup(row, \"lxml\").get_text().lower()), \n",
    "                                 movies_reviews.review))\n",
    "\n",
    "# Agregar una columna con la conversión de mensajes a listas de palabras\n",
    "# Se eliminan las palabras vacías\n",
    "stops = set(stopwords.words(\"english\"))                  \n",
    "movies_reviews[\"words\"] = list(map(lambda row: [w for w in row.split() if not w in stops], \n",
    "                                   movies_reviews.review))\n",
    "display(movies_reviews.head())\n",
    "\n",
    "# Generar un arreglo con los valores de clasificación\n",
    "Sentiments = np.array([int(x) for x in movies_reviews.sentiment])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador Bernoulli bayesiano ingenuo\n",
    "\n",
    "En este ejemplo se utilizará el modelo de Bernoulli del clasificador bayesiano ingenuo. El proceso consiste en generar una bolsa de palabras con las palabras más frecuentes en el documento y utilizar la bolsa como prototipo de vector de características. A continuación, para cada vector de entrada, el vector de características específico contiene un 1 en las posiciones correspondientes a aquellas palabras que están presentes en el documento (sin importar cuantas veces aparece) y un 0 para las palabras de la bolsa que no aparecen en el documento.\n",
    "\n",
    "![ ](images/bag-of-words-bernoulli.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 palabras más populares:\n",
      " [('movie', 44030), ('film', 40146), ('one', 26788), ('like', 20274), ('good', 15140), ('time', 12723), ('even', 12646), ('would', 12436), ('story', 11983), ('really', 11736), ('see', 11474), ('well', 10661), ('much', 9765), ('get', 9310), ('bad', 9301), ('people', 9285), ('also', 9155), ('first', 9061), ('great', 9058), ('made', 8362), ('way', 8026), ('make', 8021), ('could', 7921), ('movies', 7663), ('think', 7296), ('characters', 7154), ('character', 7022), ('watch', 6972), ('two', 6906), ('films', 6887), ('seen', 6679), ('many', 6675), ('life', 6628), ('plot', 6585), ('acting', 6490), ('never', 6484), ('love', 6453), ('little', 6435), ('best', 6414), ('show', 6294), ('know', 6166), ('ever', 5995), ('man', 5982), ('better', 5737), ('end', 5648), ('still', 5622), ('say', 5395), ('scene', 5378), ('scenes', 5207), ('go', 5156)]\n"
     ]
    }
   ],
   "source": [
    "#Regresa el vector de características de un documento\n",
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = []\n",
    "    for word in word_features:\n",
    "        if (word in document_words) :\n",
    "            features.append(1)\n",
    "        else :\n",
    "            features.append(0)\n",
    "    return features\n",
    "\n",
    "# Construcción de la Bolsa de palabras. Se seleccionan las 4000 palabras más frecuentes\n",
    "all_words = nltk.FreqDist(w.lower() for wl in movies_reviews.words for w in wl)\n",
    "print(\"50 palabras más populares:\\n\", all_words.most_common(50))\n",
    "word_features = [ w for (w,f) in all_words.most_common(4000)]\n",
    "\n",
    "# Vectores de características de la colección de documentos\n",
    "featuresetsB = [document_features(d) for d in movies_reviews[\"words\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntos mal clasificados en el conjunto de entrenamiento: 2705 de 20000 (13.525%)\n",
      "\n",
      "Puntos mal clasificados en el conjunto de prueba: 756 de 5000 (15.12%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dividir datos en dos conjuntos: entrenamiento y prueba\n",
    "cut = 4 * len(featuresetsB) // 5\n",
    "train_setB, test_setB = featuresetsB[:cut], featuresetsB[cut:]\n",
    "train_targetsetB, test_targetsetB = Sentiments[:cut], Sentiments[cut:]\n",
    "\n",
    "# Entrenamiento de un clasificador Bernouilli Bayes ingenuo\n",
    "#clfB = BernoulliNB(alpha=1.0, class_prior=None, fit_prior=False)\n",
    "clfB = BernoulliNB()\n",
    "clfB.fit(train_setB, train_targetsetB)\n",
    "\n",
    "# Pruebas del clasificador\n",
    "predictions_trainB = clfB.predict(train_setB)\n",
    "fails_trainB = np.sum(train_targetsetB  != predictions_trainB)\n",
    "print(\"Puntos mal clasificados en el conjunto de entrenamiento: {} de {} ({}%)\\n\"\n",
    "      .format(fails_trainB, len(train_setB), 100*fails_trainB/len(train_setB)))\n",
    "predictions_testB = clfB.predict(test_setB)\n",
    "fails_testB = np.sum(test_targetsetB  != predictions_testB)\n",
    "print(\"Puntos mal clasificados en el conjunto de prueba: {} de {} ({}%)\\n\"\n",
    "      .format(fails_testB, len(test_setB), 100*fails_testB/len(test_targetsetB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador bayesiano ingenuo multinomial con *tf–idf*\n",
    "\n",
    "En el siguiente ejemplo, se repite el ejemplo previo, pero utilizando el modelo multinomial con pesos [*tf–idf*](https://en.wikipedia.org/wiki/Tf–idf) del clasificador bayesiano ingenuo. \n",
    "\n",
    "#### Pesos tf–idf\n",
    "\n",
    "tf–idf (*term frequency–inverse document frequency*) es una medida de qué tan importante es una palabra en un documento dentro de una colección o un [corpus](https://en.wikipedia.org/wiki/Text_corpus). La lógica de esta medida es:\n",
    "\n",
    "* Si una palabra aparece muchas veces en un documento, es importante y debe tener un valor alto. Este es el término *tf*, típicamente calculado como la frecuencia relativa del término en el documento: <br><br>\n",
    "$$tf = \\frac{n_{td}}{n_d}$$<br>\n",
    "donde $n_{td}$ es la frecuencia de la palabra $t$ en el documento $d$ y $n_d=\\mid d\\mid$ la cantidad de palabras en el documento.<br><br>\n",
    "\n",
    "* Si una palabra aparece en muchos documentos, entonces no es discriminante. Debe tener un valor bajo. Este es el término *idf* y su expresión más simple es:<br><br>\n",
    "$$\\text{idf}(t) = log{\\frac{N}{1+\\text{df}(d,t)}}$$<br>\n",
    "donde $N=\\mid D\\mid$ es el número total de documentos en el corpus $D$ y $\\text{df}(d,t)=\\mid\\{d\\in D: t\\in d\\}\\mid$ es el número de documentos en el corpus que contienen la palabra $t$.\n",
    "\n",
    "La biblioteca *sklearn* ofrece diversas maneras de calcular los pesos *tf-idf*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntos mal clasificados en el conjunto de entrenamiento: 2702 de 20000 (13.51%)\n",
      "\n",
      "Puntos mal clasificados en el conjunto de prueba: 776 de 5000 (15.52%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculo del vector de carcterísticas, utilizano los 4000 términos más importantes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features = 4000)\n",
    "X_data = vectorizer.fit_transform(movies_reviews.review)\n",
    "\n",
    "cut = 4 * X_data.shape[0] // 5\n",
    "train_setM, test_setM = X_data[:cut], X_data[cut:]\n",
    "train_targetsetM, test_targetsetM = Sentiments[:cut], Sentiments[cut:]\n",
    "\n",
    "# Entrenamiento de un clasificador Multinomial Bayes ingenuo\n",
    "clfM = MultinomialNB()\n",
    "clfM.fit(train_setM, train_targetsetM)\n",
    "\n",
    "# Pruebas del clasificador\n",
    "predictions_trainM = clfM.predict(train_setM)\n",
    "fails_trainM = sum(train_targetsetM  != predictions_trainM)\n",
    "print(\"Puntos mal clasificados en el conjunto de entrenamiento: {} de {} ({}%)\\n\"\n",
    "      .format(fails_trainM, train_setM.shape[0], 100*fails_trainM/train_setM.shape[0]))\n",
    "predictions_testM = clfM.predict(test_setM)\n",
    "fails_testM = sum(test_targetsetM  != predictions_testM)\n",
    "print(\"Puntos mal clasificados en el conjunto de prueba: {} de {} ({}%)\\n\"\n",
    "      .format(fails_testM, test_setM.shape[0], 100*fails_testM/test_setM.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
