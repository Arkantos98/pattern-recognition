{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de patrones: Preparación de datos\n",
    "### Ramón Soto C. [(rsotoc@moviquest.com)](mailto:rsotoc@moviquest.com/)\n",
    "![ ](images/blank.png)\n",
    "![agents](images/binary_data_under_a_magnifying.jpg)\n",
    "[ver en nbviewer](http://nbviewer.ipython.org/github/rsotoc/pattern-recognition/blob/master/Datos%201.%20Intro.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición\n",
    "\n",
    "Los datos son la base de la nueva economía de la información. Cada día se generan 2.5 x 10<sup>18</sup> bytes de datos ([aquí](http://www.vcloudnews.com/every-day-big-data-statistics-2-5-quintillion-bytes-of-data-created-daily/) un interesante *infographic* al respecto), provenientes de sensores, GPSs, redes sociales, mensajes electrónicos, transacciones comerciales, publicaciones regulares, etc. Esos datos permiten generar una gran cantidad de información para atender virtualmente cualquier problema. Sin embargo, antes de poder explotar la información contenida en ellos y antes de poder generar conocimiento de utilidad para la toma de decisiones, es necesario garantizar que los datos se encuentren en 'buenas condiciones'. \n",
    "\n",
    "Es una estimación bien conocida en tre los científicos de datos que el 80% del tiempo dedicado a la solución de un problema se invierte en la preparación de los datos: \n",
    "\n",
    "![](images/time.jpg)\n",
    "![ ](images/blank.png)\n",
    "\n",
    "El proceso de mejoramiento de los datos es lo que se denomina **preparación de los datos**. \n",
    "![](images/DataPreparation.png)\n",
    "![ ](images/blank.png)\n",
    "* La *limpieza de datos* consiste en rellenar valores faltantes, suavizar datos con ruido, identificar y remover valor atípicos y resolver inconsistencias. \n",
    "* La *integración de datos* es la integración de diversas fuentes de datos: bases de datos, cubos de datos o archivos. \n",
    "* La *selección de datos* consiste en seleccionar el conjunto de datos adecuado para analizar el sistema, incluyendo el muestreo. \n",
    "* La *selección de características* es un proceso mediante el cual se analizan las variables determinantes para describir los datos. \n",
    "* La *transformación de datos* incluye operaciones como normalización, agregación, codificación. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de los datos \n",
    "\n",
    "### Datos faltantes \n",
    "\n",
    "El problema de valores faltantes es un problema muy frecuente al tratar de realizar cualquier tarea de análisis de datos y puede deberse a diversas razones: \n",
    "* Fallas en los mecanismos de medición (sensores defectuosos, por ejemplo) \n",
    "* Integración de conjuntos de datos no bien coordinados (mediciones con diferentes ciclos, por ejemplo) \n",
    "* Variables nuevas no consideradas o no disponibles originalmente \n",
    "* Respuestas omitidas intencionalmente por la fuente \n",
    "\n",
    "![](images/missingData.png)\n",
    "![ ](images/blank.png)\n",
    "\n",
    "La omisión de valores en el conjunto de datos puede tener diversos efectos y diferentes grados de impacto. En términos generales, se suelen considerar los siguientes grados de impacto, dependiendo del porcentaje de valores faltantes (*dumb rules*):\n",
    "La omisión de valores en el conjunto de datos puede tener diversos efectos y diferentes grados de impacto. En términos generales, se suelen considerar los siguientes grados de impacto, dependiendo del porcentaje de valores faltantes (*dumb rules*):\n",
    "* Menos de 1%: Trivial (no relevante)\n",
    "* 1-5%: Manejable\n",
    "* 5-15%: Manejable mediante métodos sofisticados\n",
    "* Más de 15%: Crítico, con impacto severo en cualquier tipo de interpretación\n",
    "\n",
    "Considérese el siguiente conjunto de datos tomados del conjunto de datos de diabetes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            emb        gl2h        pad        ept        is2h        imc  \\\n",
      "count  20.00000   20.000000  18.000000  11.000000    9.000000  19.000000   \n",
      "mean    4.50000  129.400000  68.555556  32.363636  258.111111  32.578947   \n",
      "std     3.56149   35.354446  16.346333   8.891262  263.487877   6.509103   \n",
      "min     0.00000   78.000000  30.000000  19.000000   83.000000  23.300000   \n",
      "25%     1.00000  106.000000  64.500000  26.000000   94.000000  27.600000   \n",
      "50%     4.50000  117.000000  71.000000  32.000000  168.000000  30.500000   \n",
      "75%     7.25000  152.500000  74.000000  36.500000  230.000000  36.450000   \n",
      "max    10.00000  197.000000  96.000000  47.000000  846.000000  45.800000   \n",
      "\n",
      "             fpd       edad     class  \n",
      "count  20.000000  20.000000  20.00000  \n",
      "mean    0.511650  37.450000   0.65000  \n",
      "std     0.513691  11.591626   0.48936  \n",
      "min     0.134000  21.000000   0.00000  \n",
      "25%     0.198500  30.750000   0.00000  \n",
      "50%     0.374500  32.000000   1.00000  \n",
      "75%     0.560000  50.250000   1.00000  \n",
      "max     2.288000  59.000000   1.00000   \n",
      "\n",
      "    emb  gl2h   pad   ept   is2h   imc    fpd  edad  class\n",
      "0     6   148  72.0  35.0    NaN  33.6  0.627    50      1\n",
      "1     1    85  66.0  29.0    NaN  26.6  0.351    31      0\n",
      "2     8   183  64.0   NaN    NaN  23.3  0.672    32      1\n",
      "3     1    89  66.0  23.0   94.0  28.1  0.167    21      0\n",
      "4     0   137  40.0  35.0  168.0  43.1  2.288    33      1\n",
      "5     5   116  74.0   NaN    NaN  25.6  0.201    30      0\n",
      "6     3    78  50.0  32.0   88.0  31.0  0.248    26      1\n",
      "7    10   115   NaN   NaN    NaN  35.3  0.134    29      0\n",
      "8     2   197  70.0  45.0  543.0  30.5  0.158    53      1\n",
      "9     8   125  96.0   NaN    NaN   NaN  0.232    54      1\n",
      "10    4   110  92.0   NaN    NaN  37.6  0.191    30      0\n",
      "11   10   168  74.0   NaN    NaN  38.0  0.537    34      1\n",
      "12   10   139  80.0   NaN    NaN  27.1  1.441    57      0\n",
      "13    1   189  60.0  23.0  846.0  30.1  0.398    59      1\n",
      "14    5   166  72.0  19.0  175.0  25.8  0.587    51      1\n",
      "15    7   100   NaN   NaN    NaN  30.0  0.484    32      1\n",
      "16    0   118  84.0  47.0  230.0  45.8  0.551    31      1\n",
      "17    7   107  74.0   NaN    NaN  29.6  0.254    31      1\n",
      "18    1   103  30.0  38.0   83.0  43.3  0.183    33      0\n",
      "19    1   115  70.0  30.0   96.0  34.6  0.529    32      1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reconocimiento de patrones: Limpieza de datos\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('Data sets/Pima Indian Data Set') \n",
    "df = pd.read_csv(\"pima-indians-diabetes.data-small\", \n",
    "                 names = ['emb', 'gl2h', 'pad', 'ept', 'is2h', 'imc', 'fpd', 'edad', 'class'])\n",
    "\n",
    "print(df.describe(), '\\n')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Como puede observarse, la variable *count* no es la misma para todas las columnas. Comparando con el despliegue de los datos, las diferencias en el valor de esta variable corresponde a los valores faltantes. Una mayor exploración podemos obtenerla de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de valores nulos\n",
      "      emb   gl2h    pad    ept   is2h    imc    fpd   edad  class\n",
      "0   False  False  False  False   True  False  False  False  False\n",
      "1   False  False  False  False   True  False  False  False  False\n",
      "2   False  False  False   True   True  False  False  False  False\n",
      "3   False  False  False  False  False  False  False  False  False\n",
      "4   False  False  False  False  False  False  False  False  False\n",
      "5   False  False  False   True   True  False  False  False  False\n",
      "6   False  False  False  False  False  False  False  False  False\n",
      "7   False  False   True   True   True  False  False  False  False\n",
      "8   False  False  False  False  False  False  False  False  False\n",
      "9   False  False  False   True   True   True  False  False  False\n",
      "10  False  False  False   True   True  False  False  False  False\n",
      "11  False  False  False   True   True  False  False  False  False\n",
      "12  False  False  False   True   True  False  False  False  False\n",
      "13  False  False  False  False  False  False  False  False  False\n",
      "14  False  False  False  False  False  False  False  False  False\n",
      "15  False  False   True   True   True  False  False  False  False\n",
      "16  False  False  False  False  False  False  False  False  False\n",
      "17  False  False  False   True   True  False  False  False  False\n",
      "18  False  False  False  False  False  False  False  False  False\n",
      "19  False  False  False  False  False  False  False  False  False \n",
      "\n",
      "Contabilidad de valores nulos por columna\n",
      "emb       0\n",
      "gl2h      0\n",
      "pad       2\n",
      "ept       9\n",
      "is2h     11\n",
      "imc       1\n",
      "fpd       0\n",
      "edad      0\n",
      "class     0\n",
      "dtype: int64 \n",
      "\n",
      "Porcentaje de datos nulos en la columna *ept*\n",
      "45.0\n"
     ]
    }
   ],
   "source": [
    "print ('Tabla de valores nulos')\n",
    "print (df.isnull(), '\\n')\n",
    "\n",
    "print ('Contabilidad de valores nulos por columna')\n",
    "print (df.isnull().sum(), '\\n')\n",
    "\n",
    "print ('Porcentaje de datos nulos en la columna *ept*')\n",
    "eptNullPje = df['ept'].isnull().sum() / df.shape[0] * 100\n",
    "print (eptNullPje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede apreciarse, el porcentaje de valores faltantes en este segmento de datos (45% de valores faltantes) está muy por encima de lo que puede tratarse de manera directa, según las reglas anteriores. \n",
    "\n",
    "En muchos casos, incluso detectar los valores faltantes es un problema. En nuestros datos originales, lo valores faltantes vienen enmascarados como 0, no como un espacio vacío. En este caso, el procedimiento anterior fallaría pues no existen datos 'no disponibles'. Debemos primero analizar los datos y detectar cómo se manifiestan los valores faltantes. En nuestro ejemplo, asumimos que *ept*, esto es, el 'Espesor de la piel del tríceps' no puede tener un valor de 0 y, por lo tanto, ese valor representa un valor faltante. Para resolver el problema, debemos preparar los datos asignando una etiqueta *NaN* a los valores que consideramos como valores'faltantes': \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    emb  gl2h  pad  ept  is2h   imc    fpd  edad  class\n",
      "0     6   148   72   35     0  33.6  0.627    50      1\n",
      "1     1    85   66   29     0  26.6  0.351    31      0\n",
      "2     8   183   64    0     0  23.3  0.672    32      1\n",
      "3     1    89   66   23    94  28.1  0.167    21      0\n",
      "4     0   137   40   35   168  43.1  2.288    33      1\n",
      "5     5   116   74    0     0  25.6  0.201    30      0\n",
      "6     3    78   50   32    88  31.0  0.248    26      1\n",
      "7    10   115    0    0     0  35.3  0.134    29      0\n",
      "8     2   197   70   45   543  30.5  0.158    53      1\n",
      "9     8   125   96    0     0   0.0  0.232    54      1\n",
      "10    4   110   92    0     0  37.6  0.191    30      0\n",
      "11   10   168   74    0     0  38.0  0.537    34      1\n",
      "12   10   139   80    0     0  27.1  1.441    57      0\n",
      "13    1   189   60   23   846  30.1  0.398    59      1\n",
      "14    5   166   72   19   175  25.8  0.587    51      1\n",
      "15    7   100    0    0     0  30.0  0.484    32      1\n",
      "16    0   118   84   47   230  45.8  0.551    31      1\n",
      "17    7   107   74    0     0  29.6  0.254    31      1\n",
      "18    1   103   30   38    83  43.3  0.183    33      0\n",
      "19    1   115   70   30    96  34.6  0.529    32      1 \n",
      "\n",
      "    emb  gl2h  pad   ept  is2h   imc    fpd  edad  class\n",
      "0     6   148   72  35.0     0  33.6  0.627    50      1\n",
      "1     1    85   66  29.0     0  26.6  0.351    31      0\n",
      "2     8   183   64   NaN     0  23.3  0.672    32      1\n",
      "3     1    89   66  23.0    94  28.1  0.167    21      0\n",
      "4     0   137   40  35.0   168  43.1  2.288    33      1\n",
      "5     5   116   74   NaN     0  25.6  0.201    30      0\n",
      "6     3    78   50  32.0    88  31.0  0.248    26      1\n",
      "7    10   115    0   NaN     0  35.3  0.134    29      0\n",
      "8     2   197   70  45.0   543  30.5  0.158    53      1\n",
      "9     8   125   96   NaN     0   0.0  0.232    54      1\n",
      "10    4   110   92   NaN     0  37.6  0.191    30      0\n",
      "11   10   168   74   NaN     0  38.0  0.537    34      1\n",
      "12   10   139   80   NaN     0  27.1  1.441    57      0\n",
      "13    1   189   60  23.0   846  30.1  0.398    59      1\n",
      "14    5   166   72  19.0   175  25.8  0.587    51      1\n",
      "15    7   100    0   NaN     0  30.0  0.484    32      1\n",
      "16    0   118   84  47.0   230  45.8  0.551    31      1\n",
      "17    7   107   74   NaN     0  29.6  0.254    31      1\n",
      "18    1   103   30  38.0    83  43.3  0.183    33      0\n",
      "19    1   115   70  30.0    96  34.6  0.529    32      1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"pima-indians-diabetes.data-small-orig\", \n",
    "                 names = ['emb', 'gl2h', 'pad', 'ept', 'is2h', 'imc', 'fpd', 'edad', 'class'])\n",
    "\n",
    "print(df, '\\n')\n",
    "\n",
    "df.loc[df['ept'] == 0,'ept'] = np.nan\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En plataformas para *data science*, como R y Pandas, los valores marcados como 'NaN' suelen ser ignorados en las operaciones: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 9 columns):\n",
      "emb      20 non-null int64\n",
      "gl2h     20 non-null int64\n",
      "pad      20 non-null int64\n",
      "ept      11 non-null float64\n",
      "is2h     20 non-null int64\n",
      "imc      20 non-null float64\n",
      "fpd      20 non-null float64\n",
      "edad     20 non-null int64\n",
      "class    20 non-null int64\n",
      "dtypes: float64(3), int64(6)\n",
      "memory usage: 1.5 KB\n",
      "None \n",
      "\n",
      "            emb        gl2h        pad        ept        is2h        imc  \\\n",
      "count  20.00000   20.000000  20.000000  11.000000   20.000000  20.000000   \n",
      "mean    4.50000  129.400000  61.700000  32.363636  116.150000  30.950000   \n",
      "std     3.56149   35.354446  26.159631   8.891262  215.843821   9.654424   \n",
      "min     0.00000   78.000000   0.000000  19.000000    0.000000   0.000000   \n",
      "25%     1.00000  106.000000  57.500000  26.000000    0.000000  26.975000   \n",
      "50%     4.50000  117.000000  70.000000  32.000000    0.000000  30.300000   \n",
      "75%     7.25000  152.500000  74.000000  36.500000  114.000000  35.875000   \n",
      "max    10.00000  197.000000  96.000000  47.000000  846.000000  45.800000   \n",
      "\n",
      "             fpd       edad     class  \n",
      "count  20.000000  20.000000  20.00000  \n",
      "mean    0.511650  37.450000   0.65000  \n",
      "std     0.513691  11.591626   0.48936  \n",
      "min     0.134000  21.000000   0.00000  \n",
      "25%     0.198500  30.750000   0.00000  \n",
      "50%     0.374500  32.000000   1.00000  \n",
      "75%     0.560000  50.250000   1.00000  \n",
      "max     2.288000  59.000000   1.00000   \n",
      "\n",
      "Suma y promedio de ept: (356.0, 32.36363636363637) \n",
      "\n",
      "Promedio tomando en cuenta los 0s: 17.8\n"
     ]
    }
   ],
   "source": [
    "print(df.info(), '\\n')\n",
    "\n",
    "print(df.describe(), '\\n')\n",
    "\n",
    "print('Suma y promedio de ept: ({}, {})'.format(df['ept'].sum(), df['ept'].mean()), '\\n')\n",
    "\n",
    "print('Promedio tomando en cuenta los 0s:', df['ept'].sum()/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2\n",
    "\n",
    "Analice los problemas de valores faltantes en el conjunto de datos *Pima Indians Diabetes* completo. \n",
    "\n",
    "**Fecha de entrega**: Martes 29 de agosto."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
